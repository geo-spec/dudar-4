# Импортируем функцию load_iris из библиотеки scikit-learn.
# Она загружает встроенный набор данных "Iris" — классический пример для обучения алгоритмов классификации.

from sklearn.datasets import load_iris
import pandas as pd

# Импортируем библиотеку pandas для работы с табличными данными (DataFrame).
# DataFrame — это как таблица Excel, но управляется через Python.

from pprint import pprint

# Загружаем набор данных Iris и сохраняем его в переменную iris.
# Функция возвращает объект типа Bunch (почти как словарь),
# в котором хранятся: данные, названия столбцов, названия классов и описание.

iris = load_iris()

# Создаем объект DataFrame (таблицу) из данных iris.
# Аргумент data=iris.data — это сами числовые данные (длина и ширина лепестков и чашелистиков).
# Аргумент columns=iris.feature_names — это список названий столбцов, чтобы таблица имела читаемые заголовки.

df = pd.DataFrame(data=iris.data, columns=iris.feature_names)

# Добавляем новый столбец 'target' в DataFrame.
# В нем хранятся числовые метки классов (0, 1, 2),
# которые соответствуют трем видам ирисов: setosa, versicolor, virginica.

df['target'] = iris.target


# Выводим первые 5 строк таблицы на экран, чтобы убедиться, что данные загружены правильно.
# Это быстрый способ "взглянуть" на структуру таблицы и убедиться, что всё в порядке.



# print(df.head())

from sklearn.model_selection import train_test_split
X = df[iris.feature_names]
y = df['target']

# X_train, X_test - данные на которых будем обучать модель

# y_train, y_test - тестовые данные для проверки модели (как хорошо модель научилась предсказывать)


X_train, X_test, y_train, y_test = train_test_split(
    iris.data, iris.target, test_size=0.2, random_state=42
)
# test_size=0.2 означает, что 20% данных уйдет на тестирование модели, а 80% останется для обучения.
# random_state=42 — это "зерно" для генератора случайных чисел (чтобы разбиение было воспроизводимым).
# если не указывать random_state, то при каждом запуске кода разбиение будет разным.

pprint(X_train[:5])
pprint(y_train[:5])

# [:5] - слайсинг, берем первые 5 элементов из массива

# pprint(iris)

# для обучения используем алгоритм ближайших соседей
from sklearn.neighbors import KNeighborsClassifier
model = KNeighborsClassifier(n_neighbors=3)
 
# n_neighbors=3 - это параметр, который указывает, что алгоритм будет использовать 3 ближайших соседа для классификации. То есть:

# Когда модель получает новый образец для классификации
# Она находит 3 ближайших к нему точки из обучающих данных
# Новому образцу присваивается тот класс, который чаще встречается среди этих трех соседей

model.fit(X_train, y_train)

# Строка model.fit(X_train, y_train) - это метод обучения модели машинного обучения. Давайте разберем подробно:

# fit() - это стандартный метод в scikit-learn для обучения модели, который:

# Принимает обучающие данные
# Настраивает внутренние параметры модели
# Запоминает обучающие примеры (для KNeighborsClassifier)
# Параметры метода:

# X_train - матрица признаков (features) для обучения

# Содержит измерения ирисов (длина и ширина лепестков/чашелистиков)
# Размер: [120 образцов × 4 признака]
# y_train - вектор целевых значений (target)

# Содержит метки классов (0, 1, 2 для разных видов ирисов)
# Размер: [120 образцов]
# В случае KNeighborsClassifier:

# Метод fit() просто сохраняет обучающие данные
# Не производит сложных вычислений
# Будет использовать эти данные позже для поиска ближайших соседей
# После выполнения этой строки модель готова делать предсказания с помощью метода predict().

accuracy = model.score(X_test, y_test)
print(f'Точность модели: {accuracy * 100:.2f}%')

# {accuracy:.2f} - это часть f-строки в Python, которая форматирует вывод точности модели. Давайте разберем ее:

# accuracy - это переменная, содержащая значение точности модели (число от 0 до 1)
# :.2f - это спецификатор формата, где:
# .2 означает, что нужно показать 2 цифры после десятичной точки
# f указывает на формат числа с плавающей точкой
# Например, если accuracy = 0.9666666666667, то вывод будет:

# Это делает вывод более читабельным, округляя длинное десятичное число до двух знаков после запятой.

import numpy as np

# Новый пример ириса для классификации
# Значения: длина и ширина чашелистика, длина и ширина леп   
example = np.array([[5.1, 3.5, 1.4, 0.2]])
predication = model.predict(example)
print(f'Предсказанный класс для примера {example[0]}: {iris.target_names[predication][0]}')
