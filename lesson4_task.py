import pandas as pd
data = {
	'age': [25, 45, 35, 22, 55, 33, 27, 40],
	'income': [50000, 90000, 65000, 40000, 120000, 70000, 48000, 80000],
	'purchased': [0, 1, 1, 0, 1, 1, 0, 1]
}

df = pd.DataFrame(data)

from pprint import pprint
pprint(df.head(7))
# Выводим все 8 строк таблицы на экран, чтобы убедиться, что данные загружены правильно.

from sklearn.model_selection import train_test_split
# X_train, X_train - данные на которых будем обучать модель
# y_test, y_test - тестовые данные для проверки модели (как хорошо модель научилась предсказывать)

pprint(df['age'])

X = df[['age', 'income']]

target = df['purchased']

# # X_train, X_test - данные на которых будем обучать модель

# # y_train, y_test - тестовые данные для проверки модели (как хорошо модель научилась предсказывать)
X_train, X_test, y_train, y_test = train_test_split(
    X, target, test_size=0.2, random_state=42
)
# pprint(X_train, X_test, y_train, y_test)

pprint(X_train)
pprint(X_test)


# Проверяем размерности данных
print("Размер тренировочной выборки:", X_train.shape)
# .shape - атрибут массива numpy, который возвращает кортеж с размерами массива по каждому измерению
print("Размер тестовой выборки:", X_test.shape)


# для обучения используем алгоритм ближайших соседей
from sklearn.neighbors import KNeighborsClassifier
model = KNeighborsClassifier(n_neighbors=3)

# n_neighbors=3 - это параметр, который указывает, что алгоритм будет использовать 3 ближайших соседа для классификации. То есть:

# Когда модель получает новый образец для классификации
# Она находит 3 ближайших к нему точки из обучающих данных
# Новому образцу присваивается тот класс, который чаще встречается среди этих трех соседей
model.fit(X_train, y_train)

# Строка model.fit(X_train, y_train) - это метод обучения модели машинного обучения. Давайте разберем подробно:

# fit() - это стандартный метод в scikit-learn для обучения модели, который:

# Принимает обучающие данные
# Настраивает внутренние параметры модели
# Запоминает обучающие примеры (для KNeighborsClassifier)
# Параметры метода:

# X_train - матрица признаков (features) для обучения

# Содержит измерения ирисов (длина и ширина лепестков/чашелистиков)
# Размер: [120 образцов × 4 признака]
# y_train - вектор целевых значений (target)


# Метод fit() просто сохраняет обучающие данные
# Не производит сложных вычислений
# Будет использовать эти данные позже для поиска ближайших соседей
# После выполнения этой строки модель готова делать предсказания с помощью метода predict().

accuracy = model.score(X_test, y_test)
print(f'Точность модели: {accuracy * 100:.2f}%')

# pprint(X_test)
# exit()
 
# {accuracy:.2f} - это часть f-строки в Python, которая форматирует вывод точности модели. Давайте разберем ее:

# accuracy - это переменная, содержащая значение точности модели (число от 0 до 1)
# :.2f - это спецификатор формата, где:
# .2 означает, что нужно показать 2 цифры после десятичной точки
# f указывает на формат числа с плавающей точкой
# Например, если accuracy = 0.9666666666667, то вывод будет:

# Это делает вывод более читабельным, округляя длинное десятичное число до двух знаков после запятой.

import numpy as np

# Новый пример заработка для классификации
# Значения: возраст = 30, доход = 60000
example = pd.DataFrame([[30, 60000]], columns=['age', 'income'])
predication = model.predict(example)


# pprint(example)
# pprint(predication)
pprint(f'Предсказанный класс для примера {example.values[0]}: {predication[0]}')

# print(f'Предсказанный класс для примера {example[0]}: {predication[0]}')

